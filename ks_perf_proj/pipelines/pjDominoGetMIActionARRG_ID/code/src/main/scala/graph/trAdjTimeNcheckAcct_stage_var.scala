package graph
import io.prophecy.libs._
import udfs.PipelineInitCode._
import udfs.UDFs._
import config.Context
import org.apache.spark._
import org.apache.spark.sql._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.expressions._
import java.time._
object trAdjTimeNcheckAcct_stage_var { def apply(context: Context, lkPibAcntLoad: DataFrame): DataFrame = lkPibAcntLoad.withColumn("svHSBCAccount", datastage_substring(col("RPS_ACCT_ID_14"), lit(1.0d), lit(2.0d)) === lit("40")).withColumn("svTIMESTAMP", col("TIMESTAMP")).withColumn("year", datastage_substring(col("svTIMESTAMP"), lit(1.0d), lit(4.0d))).withColumn("day", ds_right(ds_string_concat(lit("0"), field3(col("svTIMESTAMP"), lit("-"), lit(3.0d))), lit(2.0d))).withColumn("svInvalidHours", field3(col("svTIMESTAMP"), lit("-"), lit(4.0d)) === lit("24")).withColumn("hours", when(col("svInvalidHours"), lit(0.0d)).otherwise(field3(col("svTIMESTAMP"), lit("-"), lit(4.0d)))).withColumn("Time", ds_string_concat(ds_string_concat(ds_string_concat(ds_string_concat(ds_right(ds_string_concat(lit("0"), col("hours")), lit(2.0d)), lit(":")), field3(col("svTIMESTAMP"), lit("-"), lit(5.0d))), lit(":")), field3(col("svTIMESTAMP"), lit("-"), lit(6.0d)))).withColumn("MiliSeconds", ds_left(ds_string_concat(field3(col("svTIMESTAMP"), lit("-"), lit(7.0d)), lit("0000")), lit(6.0d))).withColumn("svADJTIMESTAMP", stringtodate(ds_string_concat(ds_string_concat(ds_string_concat(ds_string_concat(col("year"), lit("-")), field3(col("svTIMESTAMP"), lit("-"), lit(2.0d))), lit("-")), col("day")), lit("%yyyy-%mmm-%dd"))).withColumn("svNEWTIMESTAMP", ds_string_concat(ds_string_concat(ds_string_concat(ds_string_concat(col("svADJTIMESTAMP"), lit("")), col("Time")), lit(".")), col("MiliSeconds"))).withColumn("month", datastage_substring(col("svNEWTIMESTAMP"), lit(6.0d), lit(2.0d))).withColumn("date1", datastage_substring(col("svNEWTIMESTAMP"), lit(1.0d), lit(7.0d))).withColumn("date2", datastage_substring(col("svNEWTIMESTAMP"), lit(1.0d), lit(10.0d))).withColumn("LastSunday", when(col("month") === lit(3.0d) or col("month") === lit(10.0d), when(weekdayfromdate(ds_string_concat(col("date1"), lit("-25"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-25")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-26"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-26")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-27"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-27")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-28"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-28")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-29"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-29")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-30"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-30")))).when(weekdayfromdate(ds_string_concat(col("date1"), lit("-31"))) === lit(0.0d), stringtodate1(ds_string_concat(col("date1"), lit("-31")))).otherwise(lit(1.0d))).otherwise(lit(1.0d))).withColumn("TS", stringtotimestamp(col("svNEWTIMESTAMP"))).withColumn("UKLocalTime", timestampfromsecondssince(lit(3600), col("TS"))).withColumn("UKLocalTimeMiliSeconds", ds_string_concat(ds_string_concat(col("UKLocalTime"), lit(".")), col("MiliSeconds"))).withColumn("TSMiliSeconds", ds_string_concat(ds_string_concat(col("TS"), lit(".")), col("MiliSeconds"))) }